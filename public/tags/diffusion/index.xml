<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Diffusion on HasithAlted</title>
    <link>http://localhost:1313/tags/diffusion/</link>
    <description>Recent content in Diffusion on HasithAlted</description>
    <generator>Hugo -- 0.152.2</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Dec 2025 08:45:16 +0530</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/diffusion/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Lec4</title>
      <link>http://localhost:1313/posts/flowdiffusion/lec4/</link>
      <pubDate>Tue, 23 Dec 2025 08:45:16 +0530</pubDate>
      <guid>http://localhost:1313/posts/flowdiffusion/lec4/</guid>
      <description>&lt;p&gt;In &lt;a href=&#34;http://localhost:1313/posts/flowdiffusion/lec3/&#34;&gt;Lecture 3&lt;/a&gt;, we were able to develop training schemes to have a model generate samples from the data distribution. However, this is not too useful. Instead, we want to be able to condition the generation on some context, such as a class label.&lt;/p&gt;
&lt;p&gt;On the MNIST dataset, this would be like asking a model to generate an image of a specific digit, say 3, as opposed to just sampling anything from MNIST.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>In <a href="/posts/flowdiffusion/lec3/">Lecture 3</a>, we were able to develop training schemes to have a model generate samples from the data distribution. However, this is not too useful. Instead, we want to be able to condition the generation on some context, such as a class label.</p>
<p>On the MNIST dataset, this would be like asking a model to generate an image of a specific digit, say 3, as opposed to just sampling anything from MNIST.</p>
<p>Our new problem is now to learn a guided diffusion model
</p>
$$u^\theta_t: \mathbb{R}^d \times \mathcal{y}$$]]></content:encoded>
    </item>
    <item>
      <title>Lecture 3 - Flow Matching and Score Matching</title>
      <link>http://localhost:1313/posts/flowdiffusion/lec3/</link>
      <pubDate>Mon, 22 Dec 2025 05:52:20 +0530</pubDate>
      <guid>http://localhost:1313/posts/flowdiffusion/lec3/</guid>
      <description>&lt;p&gt;From &lt;a href=&#34;http://localhost:1313/posts/flowdiffusion/lec2/&#34;&gt;Lecture 2&lt;/a&gt;, we constructed $u_t^\text{target}(x)$ and $\nabla \log p_t(x)$. So, we can try to train a model to learn them for in the ODE and SDE cases, respectively.&lt;/p&gt;
&lt;h2 id=&#34;flow-matching&#34;&gt;Flow Matching&lt;/h2&gt;
&lt;p&gt;To begin with, we will consider the case of ODEs, where we need to learn the flow. A natural choice is the MSE loss with respect to the target marginal vector field. We will denote this as the flow matching loss:
&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>From <a href="/posts/flowdiffusion/lec2/">Lecture 2</a>, we constructed $u_t^\text{target}(x)$ and $\nabla \log p_t(x)$. So, we can try to train a model to learn them for in the ODE and SDE cases, respectively.</p>
<h2 id="flow-matching">Flow Matching</h2>
<p>To begin with, we will consider the case of ODEs, where we need to learn the flow. A natural choice is the MSE loss with respect to the target marginal vector field. We will denote this as the flow matching loss:
</p>
$$
\begin{align}
\mathcal{L}_{FM}(\theta) &= \underset{t \sim U,x\sim p_t}{\mathbb{E}} \left[ 
    \| u_t^\theta(x) - u_t^\text{target}(x) \|^2
\right] \\
&= \underset{t \sim U, z \sim p_{data}, x \sim p_t(\cdot | z)}{\mathbb{E}} \left[ 
    \| u_t^\theta(x) - u_t^\text{target}(x) \|^2
\right],
\end{align}
$$<p>
where $U$ denotes a uniform distribution on $[0,1]$. Though we know the form of $u_t^\text{target}$, it is still very intractable to compute. So, let&rsquo;s instead consider the much more approachable $u_t^\text{target}(x|z)$, which gives us the conditional flow matching loss:
</p>
$$
\mathcal{L}_{CFM}(\theta) = \underset{t, z, x}{\mathbb{E}} \left[ 
    \| u_t^\theta(x) - u_t^\text{target}(x | z) \|^2
\right].
$$<p>
The nice thing about $\mathcal{L}_{CFM}$ is revealed in Theorem 18, which shows that it differs from $\mathcal{L}_{FM}$ by just a constant.</p>
<blockquote>
<p><strong>Theorem 18:</strong> The marginal flow matching loss equals the conditional flow matching loss up to a constant.
</p>
$$\mathcal{L}_{FM}(\theta) = \mathcal{L}_{CFM}(\theta) + C$$<p>
Thus, we also have
</p>
$$\nabla_\theta \mathcal{L}_{FM}(\theta) = \nabla_\theta \mathcal{L}_{CFM} (\theta).$$</blockquote>
<p><strong>Proof:</strong> To show this, we begin with the definition of $\mathcal{L}_{FM}$:
</p>
$$
\begin{align*}
\mathcal{L}_{FM}(\theta) &= \underset{t, x}{\mathbb{E}} \left[ 
    \| u_t^\theta(x) - u_t^\text{target}(x) \|^2
\right] \\
&= \underset{t, x}{\mathbb{E}} \left[
    \| u_t^\theta(x) \|^2 - 2 u_t^\theta(x)^\top u_t^\text{target}(x) + \| u_t^\text{target}(x) \|^2
\right] \\
&= \underset{t, x}{\mathbb{E}} \left[ \| u_t^\theta(x) \|^2 \right] - 2 \underset{t, x}{\mathbb{E}} \left[ u_t^\theta(x)^\top u_t^\text{target}(x) \right] + C_1.
\end{align*}.
$$<p>
Where we were able to collect the last term into a constant since it doesn&rsquo;t depend on $\theta$. Now, we can rewrite the second term using the definition of $u_t^\text{target}(x)$:</p>
$$
\begin{align*}
\underset{t, x}{\mathbb{E}} \left[ u_t^\theta(x)^\top u_t^\text{target}(x) \right] &= \underset{t, x}{\mathbb{E}} \left[ u_t^\theta(x)^\top \int u_t^\text{target}(x|z) \frac{p_t(x|z) p_{data}(z)}{p_t(x)} \text{d}z \right] \\
&= \int_0^1 \int \int p_t(x) u_t^\theta(x)^\top u_t^\text{target}(x|z) \frac{p_t(x|z) p_{data}(z)}{p_t(x)} \text{d}z \text{d}x \text{d}t \\
&= \int_0^1 \int \int u_t^\theta(x)^\top u_t^\text{target}(x|z) p_t(x|z) p_{data}(z) \text{d}z \text{d}x \text{d}t \\
&= \underset{t, z, x}{\mathbb{E}} \left[ u_t^\theta(x)^\top u_t^\text{target}(x|z) \right].
\end{align*}
$$<p>Now that we have an equivalence of
</p>
$$
\underset{t, x}{\mathbb{E}} \left[ u_t^\theta(x)^\top u_t^\text{target}(x) \right] = \underset{t, z, x}{\mathbb{E}} \left[ u_t^\theta(x)^\top u_t^\text{target}(x|z) \right],
$$<p>
the rest of the proof follows trivially.</p>
<h3 id="flow-matchinf-for-gaussian-conditional-probability-paths">Flow Matchinf for Gaussian Conditional Probability Paths</h3>
<p>Recall that a Gaussian conditional probaibility path is defined as
</p>
$$p_t(\cdot, z) = \mathcal{N}(\cdot ; \alpha_t z, \beta_t^2)$$<p>
and the corresponding conditional vector field is given by
</p>
$$u_t^\text{target}(x|z) = \left( \dot{\alpha}_t - \frac{\dot{\beta}_t}{\beta_t}\alpha_t \right) z + \frac{\dot{\beta}_t}{\beta_t}x.$$<p>
Then, the conditional flow matching loss is
</p>
$$
\begin{align*}
\mathcal{L}_{CFM}(\theta) &= \underset{t, z, x}{\mathbb{E}} \left[ 
\| u_t^\theta(x) - \left( \dot{\alpha}_t - \frac{\dot{\beta}_t}{\beta_t}\alpha_t \right) z - \frac{\dot{\beta}_t}{\beta_t}x \|^2 \right] \\
&= \underset{t, z, \epsilon} {\mathbb{E}} \left[ 
\| u_t^\theta(\alpha_t z + \beta_t \epsilon) - (\dot{\alpha}_t z + \dot{\beta}_t \epsilon) \|^2
\right]
\end{align*}
$$<p>For the case when $\alpha_t = t$ and $\beta_t = 1 - t$ (referred to as the CondOT probability path), we have
</p>
$$
\mathcal{L}_{CFM}(\theta) = \underset{t, z, \epsilon} {\mathbb{E}} \left[ 
\| u_t^\theta(t z + (1 - t) \epsilon) - (z - \epsilon) \|^2
\right].
$$<h2 id="score-matching">Score Matching</h2>
<p>In the SDE case, we want to learn the score function $\nabla \log p_t(x)$. Similar to the flow matching loss, we can define the score matching loss and the more tractable conditional score matching loss as
</p>
$$
\begin{align}
\mathcal{L}_{SM}(\theta) &= \underset{t, z, x}{\mathbb{E}} \left[ 
    \| s_t^\theta(x) - \nabla \log p_t(x) \|^2
\right] \\
&= \underset{t, z, x}{\mathbb{E}} \left[ 
    \| s_t^\theta(x) - \nabla \log p_t(x | z) \|^2
\right],
\end{align}
$$<p>
where $s_t^\theta$ is the score network. With an identical proof to Theorem 18, we can show that the gradients of $\mathcal{L}_{SM}$ and $\mathcal{L}_{CSM}$ are equal.</p>
<p>One thing to note is that training the score netwrork is independent of the choice of $\sigma$ in</p>
$$
\text{d}X_t = \left[ u_t^\text{target}(X_t) + \frac{\sigma_t^2}{2} s^\theta_t(X_t) \right]\text{d}t + \sigma_t \text{d}W_t.
$$<p>In other words, during inference we can use any $\sigma_t$ we want and sample from $X_t$ correctly. Though, in practice we accumlate errors by simulating the SDE imperfectly and training errors, so there is an optimal $\sigma_t$.</p>
<h3 id="denoising-diffusion-models">Denoising Diffusion Models</h3>
<p>Denoising diffusion models (DDPMs) are diffusion models for the case of Gaussian conditional probability paths.</p>
<p>Since
</p>
$$\nabla \log p_t(x|z) = -\frac{x - \alpha_t z}{\beta_t^2},$$<p>The conditional score matching loss (after reparameterizing $x = \alpha_t z + \beta_t \epsilon$) becomes
</p>
$$
\mathcal{L}_{CSM}(\theta) = \underset{t, z, \epsilon}{\mathbb{E}} \left[ \frac{1}{\beta_t^2} 
    \left\| \beta_t s_t^\theta(\alpha_t z + \beta_t \epsilon) + \epsilon \right\|^2
\right].
$$<p>You may notice from the SDE that the diffusion model requires learning both $u_t^\text{target}$ and $\nabla \log p_t$ as opposed to a flow model which only requires learning $u_t^\text{target}$. However, with Gaussian probability paths, we can actually recover $u_t^\text{target}$ from $\nabla \log p_t$ using the following relationship:</p>
<p><strong>Proposition 1: (Conversion formula for Gaussian probability paths)</strong>
For a Gaussian probability path $p_t(x|z) = \mathcal{N}(x; \alpha_t z, \beta_t^2)$, it holds that the conditional vector field can be converted to the conditional score (and their respective marginals) using the formulas
</p>
$$
\begin{align*}
u_t^\text{target}(x|z) &= \left( \beta_t^2 \frac{\dot{\alpha}_t}{\alpha_t} - \dot{\beta}_t \beta_t \right) \nabla \log p_t(x|z) + \frac{\dot{\alpha}_t}{\alpha_t} x \\
u_t^\text{target}(x) &= \left( \beta_t^2 \frac{\dot{\alpha}_t}{\alpha_t} - \dot{\beta}_t \beta_t \right) \nabla \log p_t(x) + \frac{\dot{\alpha}_t}{\alpha_t} x
\end{align*}
$$<p><strong>Proof:</strong> The proof is mostly algebraic manipulation so here are the basic details:</p>
<ol>
<li>For the conditional vectori field, use the fact that $\nabla \log p_t(x|z) = \frac{\alpha_t z - x}{\beta_t^2}$. Then, it&rsquo;s fairly simple to rewrite $u_t^\text{target}(x|z)$ in terms of $\nabla \log p_t(x|z)$ rather than $z$</li>
<li>For the marginal vectr field, we use
$$
\begin{align*}
u_t^\text{target}(x) &= \int u_t^\text{target}(x|z) \frac{p_t(x|z) p_{data}(z)}{p_t(x)} \text{d}z \\
&= \int \left( \left( \beta_t^2 \frac{\dot{\alpha}_t}{\alpha_t} - \dot{\beta}_t \beta_t \right) \nabla \log p_t(x|z) + \frac{\dot{\alpha}_t}{\alpha_t} x \right) \frac{p_t(x|z) p_{data}(z)}{p_t(x)} \text{d}z
\end{align*}
$$
And then we use the definition of the marginal score function to complete the proof:
$$
\int \nabla \log p_t(x|z) \frac{p_t(x|z) p_{data}(z)}{p_t(x)} \text{d}z = \nabla \log p_t(x).
$$</li>
</ol>
<p>Using Proposition 1, we get the follwing conversions:
</p>
$$
\begin{align*}
u_t^\theta(x) &= \left( \beta_t^2 \frac{\dot{\alpha}_t}{\alpha_t} - \dot{\beta}_t \beta_t \right) s_t^\theta(x) + \frac{\dot{\alpha}_t}{\alpha_t} x \\
s_t^\theta(x) &= \frac{\alpha_t u_t^\theta(x) - \dot{\alpha}_t x }{\beta_t^2 \dot{\alpha}_t - \alpha_t \dot{\beta}_t \beta_t}
\end{align*}
$$<p>
(for the expression for $s_t^\theta(x)$, we assume that $\beta_t^2 \dot{\alpha}_t - \alpha_t \dot{\beta}_t \beta_t \neq 0$).</p>
<p>Thus, for Gaussian probability paths, we can train either a flow model or a score model and convert between the two using the above conversion formulas.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Hacking Nano-GPT into a Diffusion LLM</title>
      <link>http://localhost:1313/posts/25-09-29-nanodiffgpt/</link>
      <pubDate>Mon, 29 Sep 2025 19:45:01 -0500</pubDate>
      <guid>http://localhost:1313/posts/25-09-29-nanodiffgpt/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Here, I hacked together a diffusion llm implementation on nanoGPT. All the code can be found in this &lt;a href=&#34;https://github.com/hasithv/nanoDiffGPT&#34;&gt;github repo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve been really interested in &lt;a href=&#34;http://localhost:1313/posts/flowdiffusion/flowdiff/&#34;&gt;diffusion models&lt;/a&gt; lately, and a really interesting application of them is in language modeling. Specifically, I am talking about diffusion LLMs, where an LM iteratively refines a text output. For example, the &lt;a href=&#34;https://arxiv.org/abs/2502.09992&#34;&gt;LLaDa&lt;/a&gt; paper outlines a method to start from a fixed number of masked tokens and refine that window to produce a coherent output. The advantage with this is that it is able to parallelize a large number of tokens all at once, whereas autoregressive LMs can really only produce one token at a time (when not batching, as in most inferece applications).&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p><strong>Note:</strong> Here, I hacked together a diffusion llm implementation on nanoGPT. All the code can be found in this <a href="https://github.com/hasithv/nanoDiffGPT">github repo</a></p>
<p>I&rsquo;ve been really interested in <a href="/posts/flowdiffusion/flowdiff/">diffusion models</a> lately, and a really interesting application of them is in language modeling. Specifically, I am talking about diffusion LLMs, where an LM iteratively refines a text output. For example, the <a href="https://arxiv.org/abs/2502.09992">LLaDa</a> paper outlines a method to start from a fixed number of masked tokens and refine that window to produce a coherent output. The advantage with this is that it is able to parallelize a large number of tokens all at once, whereas autoregressive LMs can really only produce one token at a time (when not batching, as in most inferece applications).</p>
<p>I really like this paradigm because diffusion models are able to pick up on coarse structures in the data, then refine down to finer-grained details. In images, this is very obvious as the overall structure of the image is traced out first and then the smaller details are then filled in; in language modeling, I believe that diffusion LLMs may be very primed to do long horizon tasks as can also outline the basic end-to-end structure of the task without having to learn to parse through long text ouputs that the model itself created.</p>
<p>Anyways, LLaDa has been improved upon by <a href="https://arxiv.org/abs/2503.09573">block diffusion</a> to help bridge the gap between autoregressive models to produce more chat-bot like behavior (because a fixed length output is kind of difficult to make use of), and further descendents are still being researched such as with <a href="https://arxiv.org/abs/2505.15809">MMaDa</a>.</p>
<h2 id="does-llada-work-at-the-nano-scale">Does LLaDa work at the nano scale?</h2>
<p>Andrej Karpathy&rsquo;s nanoGPT implementation is very hackable, and I was wondering if I could alter it to simulate LLaDa on a GPT architecture.</p>
<h3 id="the-llada-algorithm">The LLaDa Algorithm</h3>
<p>The LLaDa generation algorithm is quite simple:</p>
<blockquote>
<ol>
<li>Begin with a fixed input of $L$ mask tokens, $x_1$</li>
<li>Start at time $t=1$ and fix some $N$ iterations</li>
<li>Predict the output of your tokens $\hat{x}_0 = f(x_t)$</li>
<li>Set $s=t-1/N$</li>
<li>For any unmasked tokens in $x_t$, keep them the same</li>
<li>For any masked tokens in $x_t$, replace them with the corresponding token in $\hat{x}_0$ with probability $1-s$</li>
<li>Set t = s and repeat from step (3) again until $s=0$</li>
</ol>
</blockquote>
<p>And the training algorithm is even simpler:</p>
<blockquote>
<ol>
<li>Each sample in a batch will be of some fixed size $L$</li>
<li>For a sample, pick some probability $p$ to mask each token</li>
<li>Predict the original, unmasked sample from the masked one.</li>
<li>Compute CE loss between the predicted tokens that were masked and the actual tokens</li>
</ol>
</blockquote>
<h3 id="implementation">Implementation</h3>
<p>As you can see, it can&rsquo;t be very hard to hack nanoGPT to do this. All we will need to do is introduce a mask token to the vocab, and edit the training loop and the generate function. The full edits are given below:</p>
<h4 id="adding-the-mask-token">Adding the <code>&lt;|MASK|&gt;</code> Token</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#75715e"># get all the unique characters that occur in this text</span>
</span></span><span style="display:flex;"><span>chars <span style="color:#f92672">=</span> sorted(list(set(data)))<span style="color:#f92672">+</span>[<span style="color:#e6db74">&#39;&lt;|MASK|&gt;&#39;</span>]
</span></span><span style="display:flex;"><span>vocab_size <span style="color:#f92672">=</span> len(chars)
</span></span></code></pre></div><h4 id="editing-training-loop">Editing Training Loop</h4>
<p>Editing the training loop consisted of two steps. First, we need to edit the way we generate data to randomly mask tokens with some probability for each sample</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_batch</span>(split):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># We recreate np.memmap every batch to avoid a memory leak, as per</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> split <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;train&#39;</span>:
</span></span><span style="display:flex;"><span>        data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>memmap(os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(data_dir, <span style="color:#e6db74">&#39;train.bin&#39;</span>), dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>uint16, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;r&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>memmap(os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(data_dir, <span style="color:#e6db74">&#39;val.bin&#39;</span>), dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>uint16, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;r&#39;</span>)
</span></span><span style="display:flex;"><span>    ix <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randint(len(data) <span style="color:#f92672">-</span> block_size, (batch_size,))
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>stack([torch<span style="color:#f92672">.</span>from_numpy((data[i:i<span style="color:#f92672">+</span>block_size])<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>int64)) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> ix])
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># &lt;---NEW CODE---&gt;</span>
</span></span><span style="display:flex;"><span>    y <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>clone()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    tok_mask_prob <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(batch_size)
</span></span><span style="display:flex;"><span>    tok_mask_prob <span style="color:#f92672">=</span> tok_mask_prob<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>repeat(<span style="color:#ae81ff">1</span>, block_size)
</span></span><span style="display:flex;"><span>    mask <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(batch_size, block_size) <span style="color:#f92672">&lt;</span> tok_mask_prob
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>masked_fill(mask, meta_vocab_size <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>) <span style="color:#75715e"># &lt;|MASK|&gt; (last token in the vocabulary)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># &lt;---NEW CODE---&gt;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> device_type <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;cuda&#39;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)</span>
</span></span><span style="display:flex;"><span>        x, y <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>pin_memory()<span style="color:#f92672">.</span>to(device, non_blocking<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>), y<span style="color:#f92672">.</span>pin_memory()<span style="color:#f92672">.</span>to(device, non_blocking<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        x, y <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>to(device), y<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> x, y
</span></span></code></pre></div><p>Then, we need to edit the forward pass to predict the unmasked tokens and then compute the CE loss:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, idx, targets<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>    device <span style="color:#f92672">=</span> idx<span style="color:#f92672">.</span>device
</span></span><span style="display:flex;"><span>    b, t <span style="color:#f92672">=</span> idx<span style="color:#f92672">.</span>size()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">assert</span> t <span style="color:#f92672">&lt;=</span> self<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>block_size, <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Cannot forward sequence of length </span><span style="color:#e6db74">{</span>t<span style="color:#e6db74">}</span><span style="color:#e6db74">, block size is only </span><span style="color:#e6db74">{</span>self<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>block_size<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>    pos <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>, t, dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>long, device<span style="color:#f92672">=</span>device) <span style="color:#75715e"># shape (t)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># forward the GPT model itself</span>
</span></span><span style="display:flex;"><span>    tok_emb <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>transformer<span style="color:#f92672">.</span>wte(idx) <span style="color:#75715e"># token embeddings of shape (b, t, n_embd)</span>
</span></span><span style="display:flex;"><span>    pos_emb <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>transformer<span style="color:#f92672">.</span>wpe(pos) <span style="color:#75715e"># position embeddings of shape (t, n_embd)</span>
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>transformer<span style="color:#f92672">.</span>drop(tok_emb <span style="color:#f92672">+</span> pos_emb)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> block <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>transformer<span style="color:#f92672">.</span>h:
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> block(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>transformer<span style="color:#f92672">.</span>ln_f(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> targets <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># if we are given some desired targets also calculate the loss</span>
</span></span><span style="display:flex;"><span>        logits <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>lm_head(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># &lt;---NEW CODE---&gt;</span>
</span></span><span style="display:flex;"><span>        mask_id <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>vocab_size <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        idx_masked <span style="color:#f92672">=</span> (idx <span style="color:#f92672">==</span> mask_id)
</span></span><span style="display:flex;"><span>        idx_masked_tok_logits <span style="color:#f92672">=</span> logits[idx_masked, :]
</span></span><span style="display:flex;"><span>        targets_masked <span style="color:#f92672">=</span> targets[idx_masked]
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># CE loss</span>
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>cross_entropy(idx_masked_tok_logits, targets_masked, reduction<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;mean&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># &lt;---NEW CODE---&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># inference-time mini-optimization: only forward the lm_head on the very last position</span>
</span></span><span style="display:flex;"><span>        logits <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>lm_head(x) <span style="color:#75715e"># note: using list [-1] to preserve the time dim</span>
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> logits, loss
</span></span></code></pre></div><h4 id="editing-the-generation-function">Editing the Generation Function</h4>
<p>Out of everything, the generation function took the longest time to implement because it is very different from autoregressive generation. For that reason, practically the entire generate function had to be rewritten:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#a6e22e">@torch.no_grad</span>()
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generate</span>(self, max_new_tokens, iters<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>, top_k<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># assert top_k==None or top_k==1</span>
</span></span><span style="display:flex;"><span>    mask_id <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>vocab_size <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    rt <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>full((<span style="color:#ae81ff">1</span>,max_new_tokens), mask_id)<span style="color:#f92672">.</span>to(<span style="color:#e6db74">&#34;cuda&#34;</span>)
</span></span><span style="display:flex;"><span>    t <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(iters):
</span></span><span style="display:flex;"><span>        s <span style="color:#f92672">=</span> t <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>iters
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># greedy sample an r0 prediction from a forward pass</span>
</span></span><span style="display:flex;"><span>        logits, _ <span style="color:#f92672">=</span> self(rt)
</span></span><span style="display:flex;"><span>        logits <span style="color:#f92672">=</span> logits<span style="color:#f92672">/</span>temperature
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> top_k <span style="color:#f92672">is</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            r0 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>argmax(logits, dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Get the top k logits and their indices</span>
</span></span><span style="display:flex;"><span>            v_size <span style="color:#f92672">=</span> logits<span style="color:#f92672">.</span>size(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            top_k_logits, top_k_indices <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>topk(logits, min(top_k, v_size), dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Create a new tensor with -inf everywhere</span>
</span></span><span style="display:flex;"><span>            new_logits <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>full_like(logits, float(<span style="color:#e6db74">&#39;-inf&#39;</span>))
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Scatter the top k logits back to their original positions</span>
</span></span><span style="display:flex;"><span>            new_logits<span style="color:#f92672">.</span>scatter_(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, top_k_indices, top_k_logits)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Replace the original logits with the filtered ones</span>
</span></span><span style="display:flex;"><span>            logits <span style="color:#f92672">=</span> new_logits
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># apply softmax to convert logits to (normalized) probabilities</span>
</span></span><span style="display:flex;"><span>            probs <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>softmax(logits, dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># sample from the distribution</span>
</span></span><span style="display:flex;"><span>            idx <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>multinomial(probs<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, probs<span style="color:#f92672">.</span>size(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)), num_samples<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            r0 <span style="color:#f92672">=</span> idx<span style="color:#f92672">.</span>view(probs<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>), probs<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># if token is not previously masked, then it shouldn&#39;t be changed</span>
</span></span><span style="display:flex;"><span>        was_masked <span style="color:#f92672">=</span> (rt <span style="color:#f92672">==</span> mask_id)
</span></span><span style="display:flex;"><span>        r0[<span style="color:#f92672">~</span>was_masked] <span style="color:#f92672">=</span> rt[<span style="color:#f92672">~</span>was_masked]
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># for each previously masked token, with prob s/t mask it again</span>
</span></span><span style="display:flex;"><span>        remask <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>full(was_masked<span style="color:#f92672">.</span>shape, s<span style="color:#f92672">/</span>t)<span style="color:#f92672">.</span>to(<span style="color:#e6db74">&#34;cuda&#34;</span>) <span style="color:#f92672">&gt;</span> torch<span style="color:#f92672">.</span>rand(was_masked<span style="color:#f92672">.</span>shape)<span style="color:#f92672">.</span>to(<span style="color:#e6db74">&#34;cuda&#34;</span>)
</span></span><span style="display:flex;"><span>        remask <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>bitwise_and(remask, was_masked)
</span></span><span style="display:flex;"><span>        r0[remask] <span style="color:#f92672">=</span> mask_id
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        t <span style="color:#f92672">=</span> s
</span></span><span style="display:flex;"><span>        rt <span style="color:#f92672">=</span> r0<span style="color:#f92672">.</span>clone()<span style="color:#f92672">.</span>to(<span style="color:#e6db74">&#34;cuda&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> rt
</span></span></code></pre></div><h3 id="training-details">Training Details</h3>
<p>Due to compute+time restraints, I only trained nanogpt on shakespeare and treated individual characters as tokens. I wanted to edit as little things as possible from the out-of-the-box, autoregressive nanoGPT config for the shakespeare char dataset.</p>
<p>The only things I ended up needing to edit was the batch size and the block size. The block size increase was needed because diffusion LLMs (at least LLaDa) can only generate a fixed size output, so to get comparable output lengths as nanoGPT I had to make that change. The batch size was increase I felt was also needed because for the model to learn the different denoising steps, we need more data at different noise levels.</p>
<p>Because of this, I am getting the idea that diffusion LLMs just take longer to train in general, but this pays dividends during inference where it is much, much faster. Plus, implementations like block diffusion are able to make the best of both worlds.</p>
<p>Relevant config parameters:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>gradient_accumulation_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">256</span>
</span></span><span style="display:flex;"><span>block_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">1024</span> <span style="color:#75715e"># context of up to 256 previous characters</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># baby GPT model :)</span>
</span></span><span style="display:flex;"><span>n_layer <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span>
</span></span><span style="display:flex;"><span>n_head <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span>
</span></span><span style="display:flex;"><span>n_embd <span style="color:#f92672">=</span> <span style="color:#ae81ff">384</span>
</span></span><span style="display:flex;"><span>dropout <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>learning_rate <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-3</span> <span style="color:#75715e"># with baby networks can afford to go a bit higher</span>
</span></span><span style="display:flex;"><span>max_iters <span style="color:#f92672">=</span> <span style="color:#ae81ff">5000</span>
</span></span><span style="display:flex;"><span>lr_decay_iters <span style="color:#f92672">=</span> <span style="color:#ae81ff">5000</span> <span style="color:#75715e"># make equal to max_iters usually</span>
</span></span><span style="display:flex;"><span>min_lr <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-4</span> <span style="color:#75715e"># learning_rate / 10 usually</span>
</span></span><span style="display:flex;"><span>beta2 <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.99</span> <span style="color:#75715e"># make a bit bigger because number of tokens per iter is small</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>warmup_iters <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span> <span style="color:#75715e"># not super necessary potentially</span>
</span></span></code></pre></div><h3 id="results">Results</h3>
<p>Considering that the dataset was so small and that each token was an individual character, I was pleasantly surprised that the diffusion LLM implementation was able to pick up on basic spelling and some very rudimentary dialogue structure.</p>
<p>Here is some example output from the diffusion LLM</p>
<pre tabindex="0"><code>lady, how doth sit not for ever young shame,
give me set to the while and there are fled to your head?

PARIS:
The gods hath no more till entertain&#39;d you.

JULIET:
Hand, peace! ye how not! but she was a full for him!
Now, marry, to see me, how she was some fear in sharp,
That it will still report his that quite himself,
Cold copes him to hear some but ransom.

ROMEO:
Proclaim me to fear, stay his love.
I would be content for the burthen on him.

JULIET:
An if I would do me a lord which I can;
Th
</code></pre><p>And compared that to Karpath&rsquo;s example nanoGPT output (I reproduced similar results):</p>
<pre tabindex="0"><code>ANGELO:
And cowards it be strawn to my bed,
And thrust the gates of my threats,
Because he that ale away, and hang&#39;d
An one with him.

DUKE VINCENTIO:
I thank your eyes against it.

DUKE VINCENTIO:
Then will answer him to save the malm:
And what have you tyrannous shall do this?

DUKE VINCENTIO:
If you have done evils of all disposition
To end his power, the day of thrust for a common men
That I leave, to fight with over-liking
Hasting in a roseman.
</code></pre><p>Clearly, the autoregressive implementation is better, and that is even reflected in the per-token validation loss curves on wandb:
<figure class="align-center ">
    <img loading="lazy" src="./images/valloss.png#center"
         alt="Validation loss between the autoregressive, default nanoGPT and the diffusion LLM implementation on shakespeare char. Computed per token for autoregressive and per masked token for diffusion." width="800px"/> <figcaption>
            <p>Validation loss between the autoregressive, default nanoGPT and the diffusion LLM implementation on shakespeare char. Computed per token for autoregressive and per masked token for diffusion.</p>
        </figcaption>
</figure>
</p>
<p>The training losses are much further apart because training includes samples that predict the original text from full noise (all masked tokens), which is not a feasible target. Compare this to the autoregressive implementation which only ever has to predict one token at a time given the previous context.
<figure class="align-center ">
    <img loading="lazy" src="./images/trainloss.png#center"
         alt="Train loss between the autoregressive, default nanoGPT and the diffusion LLM implementation on shakespeare char. Computed per token for autoregressive and per masked token for diffusion. Note that the gap between final losses is wider in the train set vs the val set. This is due to the training objectivefor the diffusion LLM to be &lsquo;harder&rsquo; in some cases, such as having to predict nearly the entire block from pure masked tokens." width="800px"/> <figcaption>
            <p>Train loss between the autoregressive, default nanoGPT and the diffusion LLM implementation on shakespeare char. Computed per token for autoregressive and per masked token for diffusion. Note that the gap between final losses is wider in the train set vs the val set. This is due to the training objectivefor the diffusion LLM to be &lsquo;harder&rsquo; in some cases, such as having to predict nearly the entire block from pure masked tokens.</p>
        </figcaption>
</figure>
</p>
<h2 id="conclusion-and-final-thoughts">Conclusion and Final Thoughts</h2>
<p>I consider this experiment a success because I was able to replicate the LLaDa training and generation algorithm to produce comparable results to the autoregressive implementation.</p>
<p>While I am happy that it works, I still am not convinced that using fixed mask tokens and gradually unmasking tokens during the generation process is the best way to construct an LLM using the foundations of diffusion. The part that I&rsquo;m the most shaky on is how masking corresponds to adding and subtracting noise. Diffusion models have so much mathematical machinery backing them, and it seems to me that using the mask token haphazardly like this kind of strays from what we have guarantees for. I&rsquo;m sure there must be better implementations that are closer to image diffusion model implementations.</p>
<p>It was a fun little experiment to convert nanoGPT into a diffusion LLM. I&rsquo;ve been thinking of other experiments on how to hijack architectures to make them do what I want, and so doing this was a good proof of concept as to how well it would work. Additionally, I got to explore diffusion LLMs, an area which I think holds tons of promise.</p>
<h2 id="references">References</h2>
<p>[1] GitHub repo - nanoDiffGPT: <a href="https://github.com/hasithv/nanoDiffGPT">https://github.com/hasithv/nanoDiffGPT</a></p>
<p>[2] Diffusion notes: <a href="/posts/flowdiffusion/flowdiff/">http://localhost:1313/posts/flowdiffusion/flowdiff/</a></p>
<p>[3] LLaDa paper: <a href="https://arxiv.org/abs/2502.09992">https://arxiv.org/abs/2502.09992</a></p>
<p>[4] Block diffusion paper: <a href="https://arxiv.org/abs/2503.09573">https://arxiv.org/abs/2503.09573</a></p>
<p>[5] MMaDa paper: <a href="https://arxiv.org/abs/2505.15809">https://arxiv.org/abs/2505.15809</a></p>
]]></content:encoded>
    </item>
    <item>
      <title>Lecture 2 - Constructing the Training Target</title>
      <link>http://localhost:1313/posts/flowdiffusion/lec2/</link>
      <pubDate>Mon, 22 Sep 2025 17:48:55 -0500</pubDate>
      <guid>http://localhost:1313/posts/flowdiffusion/lec2/</guid>
      <description>&lt;p&gt;To summarize &lt;a href=&#34;http://localhost:1313/posts/flowdiffusion/lec1/&#34;&gt;Lecture 1&lt;/a&gt;, we (given an $X_0 \sim p_{init}$) a flow model and a diffusion model to obtain trajectories from by solving the ODE and SDE,
&lt;/p&gt;
$$
\begin{align*}
\text{d}X_t &amp;= u_t^\theta(X_t) \text{d}t \\
X_t &amp;= u_t^\theta(X_t) \text{d}t + \sigma_t \text{d}W_t,
\end{align*}
$$&lt;p&gt;
respectively. Now, our goal is to find the parameters $\theta$ that make $u_t^\theta$ a good approximation of our target vector field $u_t^\text{target}$. A simple loss function we could use is the mean squared error:
&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>To summarize <a href="/posts/flowdiffusion/lec1/">Lecture 1</a>, we (given an $X_0 \sim p_{init}$) a flow model and a diffusion model to obtain trajectories from by solving the ODE and SDE,
</p>
$$
\begin{align*}
\text{d}X_t &= u_t^\theta(X_t) \text{d}t \\
X_t &= u_t^\theta(X_t) \text{d}t + \sigma_t \text{d}W_t,
\end{align*}
$$<p>
respectively. Now, our goal is to find the parameters $\theta$ that make $u_t^\theta$ a good approximation of our target vector field $u_t^\text{target}$. A simple loss function we could use is the mean squared error:
</p>
$$
\mathcal{L} = \mathbb{E}_{X_0 \sim p_{init}} \left[ \| u_t^\theta(X_t) - u_t^\text{target}(X_t) \|^2 \right].
$$<p>
But to compute this loss, we need to know $u_t^\text{target}(X_t)$.</p>
<h2 id="constructing-the-training-target">Constructing the Training Target</h2>
<h3 id="odes">ODEs</h3>
<p>The first insight in computing $u_t^\text{target}$ is to notice that the conditional probability path, $p_t(x|z)$ is much easier to find analytically than the marginal probability path. For example, with the Gaussian probability path, we can write
</p>
$$
p_t(x|z) = \mathcal{N}(\alpha_t z; \beta_t^2 I_d),
$$<p>
for monotic noise schedulers $\alpha_t$ and $\beta_t$ that satisfy $\alpha_0 = \beta_1 = 0$ and $\alpha_1 = \beta_0 = 1$. Note that for an initial $X_0 \sim p_{init}$, we have $p_0(x) = p_{init}$ and $p_1(x) = p_{data}(z) = \delta_z$.</p>
<p>Similarly, it is also easier to find the conditional vector field $u_t^\text{target}$ than the marginal vector field $u_t^\text{target}(x|z)$. The conditional vector field for the Gaussian probability path can be found with by first defining the conditional flow model
</p>
$$\psi_t^\text{target} = \alpha_t z + \beta_t x,$$<p>
where $\alpha_t \rightarrow 1$ and $\beta_t \rightarrow 0$ as $t \rightarrow 1$. The only thing that $\psi_t^\text{target}$ needs to do is transform $p_{init}$ to $p_{data}(z)$, which is easy to verify that it does.</p>
<p>Then, we can solve the ODE for $\psi_t^\text{target}$ to get $u_t^\text{target}$:
</p>
$$
\begin{align*}
\frac{\text{d}}{\text{d}t} \psi_t^\text{target}(x) &= u_t^\text{target}(\psi_t^\text{target}(x | z)| z) \\
\dot{\alpha_t}z + \dot{\beta_t}x &= u_t^\text{target}(\alpha_t z + \beta_t x | z) \\
\dot{\alpha_t} z + \dot{\beta_t} \left( \frac{x - \alpha_t z}{\beta_t} \right) &= u_t^\text{target}(x | z) \\
\left( \dot{\alpha_t} - \frac{\dot{\beta_t}}{\beta_t} \right) z + \frac{\dot{\beta_t}}{\beta_t} x &= u_t^\text{target}(x | z).
\end{align*}
$$<p>So, now, we have analytical expressions for $p_t(x|z)$ and $u_t^\text{target}(x|z)$. Using these, we can use the continuity equation to find the target vector field $u_t^\text{target}(x)$:</p>
<blockquote>
<p><strong>Theorem 12:</strong> (Continuity Equation) Consider a flow model with vector field $u_t^\text{target}$ with $X_0 \sim p_{init}$. Then, $X_t \sim p_t$ if and only if
</p>
$$ \dot{p_t} = - \nabla \cdot (u_t^\text{target} p_t)(x) $$</blockquote>
<p>Now, to construct $u_t^\text{target}$, we just need to find what vector field will satisfy the continuity equation:</p>
$$
\begin{align*}
\dot{p_t} &= \partial_t \int p_t(x|z) p_{data}(z) \text{d}z \\
&= \int \partial_t p_t(x|z) p_{data}(z) \text{d}z \\
&= \int - \nabla \cdot \left(u_t^\text{target}(\cdot | z) p_t(\cdot |z)\right)(x) p_{data}(z) \text{d}z \\
&= - \nabla \cdot \int u_t^\text{target}(x|z) p_t(x|z) p_{data}(z) \text{d}z \\
&= - \nabla \cdot \left( p_t(x) \int u_t^\text{target}(x|z) \frac{p_t(x|z) p_{data}(z)}{p_t(x)} \text{d}z \right)
\end{align*}
$$<p>So, we have that $\dot{p_t} = - \nabla \cdot (u_t^\text{target} p_t)(x)$ if and only if
</p>
$$
u_t^\text{target}(x) = \frac{p_t(x|z) p_{data}(z)}{p_t(x)}.
$$<blockquote>
<p><strong>Theorem 10:</strong> (Marginalization Trick) Let $u_t^\text{target}$ be a conditional vector field defined so that the ODE yields the conditional probability path $p_t(\cdot|z)$
</p>
$$
X_0 \sim p_{init}, \quad \frac{\text{d}}{\text{d}t} X_t = u_t^\text{target}(X_t) \implies X_t \sim p_t(\cdot|z).
$$<p>
Then, the marginal vector field $u_t^\text{target}$ given by
</p>
$$
u_t^\text{target}(x) = \int u_t^\text{target}(x|z) \frac{p_t(x|z) p_{data}(z)}{p_t(x)} \text{d}z
$$<p>
will yield the marginal probability path $p_t$:
</p>
$$
X_0 \sim p_{init}, \quad \frac{\text{d}}{\text{d}t} X_t = u_t^\text{target}(X_t) \implies X_t \sim p_t.
$$<p>
In other words, $u_t^\text{target}$ converts $p_{init}$ to $p_data$.</p>
</blockquote>
<h3 id="sdes">SDEs</h3>
<p>For SDEs, we express the marginal score function in terms of the conditional score function:
</p>
$$\nabla \log p_t(x) = \frac{\nabla p_t(x)}{p_t(x)} = \int \frac{\nabla p_t(x|z)}{p_t(x|z)} p_{data}(z) \text{d}z = \int \nabla \log p_t(x|z) p_{data}(z) \text{d}z.$$<p>Then, using the Fokker-Planck equation:</p>
<blockquote>
<p><strong>Theorem 15:</strong> (Fokker-Planck Equation) Let $p_t$ be a probability path and consider the SDE
</p>
$$ X_0 \sim p_{init}, \quad \text{d}X_t = u_t^\text{target}(X_t) \text{d}t + \sigma_t \text{d}W_t. $$<p>
Then, the score function $\nabla \log p_t(x)$ satisfies the Fokker-Planck equation:
</p>
$$
\partial_t p_t(x) = - \nabla \cdot \left(u_t^\text{target} p_t\right)(x) + \frac{\sigma_t^2}{2} \Delta p_t(x).
$$</blockquote>
<p>we can prove in a similar way to the ODE case that the SDE given by
</p>
$$X_0 \sim p_{init}, \quad \text{d}X_t = \left[ u_t^\text{target}(X_t) + \frac{\sigma_t^2}{2} \nabla \log p_t(X_t) \right] \text{d}t + \sigma_t \text{d}W_t$$<p>
will follow the probability path $p_t$.</p>
<p>The proof will be skipped, but as a hint, we begin with the continuity equation, add and subtract $\frac{\sigma_t^2}{2} \Delta p_t(x)$, then use that $\Delta = \nabla \cdot \nabla$ to get it in the form of the Fokker-Planck equation.</p>
<blockquote>
<p><strong>Theorem 13:</strong> (SDE Extension Trick) Define the conditional and marginal vector fields $u_t^\text{target}(x|z)$ and $u_t^\text{target}(x)$ as in Theorem 10. Then, for a diffusion coefficient $\sigma_t \leq 0$ the SDE
</p>
$$
X_0 \sim p_{init}, \quad \text{d}X_t = \left[ u_t^\text{target}(X_t) + \frac{\sigma_t^2}{2} \nabla \log p_t(X_t) \right] \text{d}t + \sigma_t \text{d}W_t \implies X_t \sim p_t.
$$<p>
will yield the same marginal probability path $p_t$.</p>
</blockquote>
<p>Again, Theorem 13 is useful since it allows us to express $\nabla \log p_t(x)$ in terms of $\nabla \log p_t(x|z)$.</p>
<p>Finally, I&rsquo;d like to connect the SDE above to Langevin dynamics. In the case where the probability path is static ($p_t = p$) and $u_t^{\text{target}} = 0$, we obtain the SDE
</p>
$$dX_t = \frac{\sigma^2_t}{2} \nabla \log p(X_t) dt + \sigma_t dW_t.$$<p>
This special case is known as Langevin dynamics, and you can kind of get an idea of how the SDE evolves since it satisifes the Fokker-Planck equation&ndash;meaning if $X_0 \sim p_{init}$, then $X_t \sim p$ for $t \geq 0$.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Introduction to Flow Matching and Diffusion Models</title>
      <link>http://localhost:1313/posts/flowdiffusion/flowdiff/</link>
      <pubDate>Tue, 16 Sep 2025 19:54:25 -0500</pubDate>
      <guid>http://localhost:1313/posts/flowdiffusion/flowdiff/</guid>
      <description>&lt;p&gt;Here are my notes for MIT CSAIL&amp;rsquo;s course titled &lt;a href=&#34;https://diffusion.csail.mit.edu/&#34;&gt;&lt;em&gt;Introduction to Flow Matching and Diffusion Models&lt;/em&gt;&lt;/a&gt;. While I am finding the labs very helpful and making sure I do them, I will not be documenting my progress on them here.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lecture 1 - &lt;a href=&#34;http://localhost:1313/posts/flowdiffusion/lec1/&#34;&gt;Flow and Diffusion Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lecture 2 - &lt;a href=&#34;http://localhost:1313/posts/flowdiffusion/lec2/&#34;&gt;Constructing the Training Target&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lecture 3 - &lt;a href=&#34;http://localhost:1313/posts/flowdiffusion/lec3/&#34;&gt;Flow Matching and Score Matching&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      <content:encoded><![CDATA[<p>Here are my notes for MIT CSAIL&rsquo;s course titled <a href="https://diffusion.csail.mit.edu/"><em>Introduction to Flow Matching and Diffusion Models</em></a>. While I am finding the labs very helpful and making sure I do them, I will not be documenting my progress on them here.</p>
<ul>
<li>Lecture 1 - <a href="/posts/flowdiffusion/lec1/">Flow and Diffusion Models</a></li>
<li>Lecture 2 - <a href="/posts/flowdiffusion/lec2/">Constructing the Training Target</a></li>
<li>Lecture 3 - <a href="/posts/flowdiffusion/lec3/">Flow Matching and Score Matching</a></li>
</ul>
]]></content:encoded>
    </item>
  </channel>
</rss>
