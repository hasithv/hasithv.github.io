<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Probability on HasItHalted</title>
    <link>https://hasithv.github.io/tags/probability/</link>
    <description>Recent content in Probability on HasItHalted</description>
    <generator>Hugo -- 0.129.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 03 Aug 2024 18:57:02 -0700</lastBuildDate>
    <atom:link href="https://hasithv.github.io/tags/probability/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>5.2 - Filtration and Stopping Time</title>
      <link>https://hasithv.github.io/posts/notes/eliasa/chap5/5-2/</link>
      <pubDate>Sat, 03 Aug 2024 18:57:02 -0700</pubDate>
      <guid>https://hasithv.github.io/posts/notes/eliasa/chap5/5-2/</guid>
      <description>Filtration Definition 5.3: (Filtration). Given a probability space, the filtration is a nondecreaseing family of $\sigma$-algebras $\{\mathcal{F}_t\}_{t \leq 0}$ such that $\mathcal{F}_s \subset \mathcal{F}_t \subset \mathcal{F}$ for all $0 \leq s &lt; t$.
Intuitively, the filtration is a sigma algebra of events that can be determined before time $t$ (we can&amp;rsquo;t lose information by foing forward in time). A stochastic process is called $\mathcal{F}_t$-adapted if it is measurable with respect to $\mathcal{F}_t$; that is, for all $B \in \mathcal{R}$, $X_t^{-1}(B) \in \mathcal{F}_t$.</description>
      <content:encoded><![CDATA[<h2 id="filtration">Filtration</h2>
<blockquote>
<p><strong>Definition 5.3:</strong> (Filtration). Given a probability space, the filtration is a nondecreaseing family of $\sigma$-algebras $\{\mathcal{F}_t\}_{t \leq 0}$ such that $\mathcal{F}_s \subset \mathcal{F}_t \subset \mathcal{F}$ for all $0 \leq s < t$.</p>
</blockquote>
<p>Intuitively, the filtration is a sigma algebra of events that can be determined before time $t$ (we can&rsquo;t lose information by foing forward in time). A stochastic process is called <em>$\mathcal{F}_t$-adapted</em> if it is measurable with respect to $\mathcal{F}_t$; that is, for all $B \in \mathcal{R}$, $X_t^{-1}(B) \in \mathcal{F}_t$. We can always assume that the $\mathcal{F}_t$ contains $F_t^{X}$ and all sets of measure zero, where $F_t^{X} = \sigma(X_s, s \leq t)$ is the sigma algebra generated by the process $X$ up to time $t$.</p>
<p>As an example, in a series of coin flips, when $n=0$
</p>
$$\mathcal{F}_0^X = \{\emptyset, \Omega\}$$
<p>
and when $n=1$,
</p>
$$\mathcal{F}_1^X = \{\emptyset, \Omega, \{H\}, \{T\}\}$$
<p>
when $n=2$,
</p>
$$\mathcal{F}_2^X = \sigma(\{\emptyset, \{HH\}, \{TT\}, \{HT\}, \{TH\} \})$$
<p>
(I believe this last statement is equivalent to what the book has)</p>
<h2 id="stopping-time">Stopping Time</h2>
<blockquote>
<p><strong>Definition 5.4:</strong> (Stopping time for discrete time stochastic processes). A stopping time is a random variable $T$ taking values in $\{1,2,\ldots\}\cup \{\infty\}$ such that for any $n < \infty$,
</p>
$$\{T \leq n\} \in \mathcal{F}_n$$
</blockquote>
<p>For the discrete case, it doesn&rsquo;t matter if we say $\{T \leq n\}$ or $\{T = n\}$ simply becase it has to be satisfied for all $n$.</p>
<blockquote>
<p><strong>Proposition 5.5:</strong> (Properties of stopping times). For the Markov process $\{X_n\}_{n \in \mathbb{N}}$, we have</p>
<ul>
<li>(1) if $T_1, T_2$ are stopping times, then $T_1 \wedge T_2, T_1 \vee T_2, T_1 + T_2$ are stopping times</li>
<li>(2) if $\{T_k\}_{k \geq 1}$ are stopping times then $\sup_k T_k, \inf_k T_k, \limsup_k T_k, \liminf_k T_k$ are stopping times</li>
</ul>
</blockquote>
<blockquote>
<p><strong>Definition 5.6:</strong> (Stopping time for continuous time stochastic processes). A stopping time is a random variable $T$ taking values in $[0,\infty]$ such that for any $t \in \mathbb{\bar{R}}^+$,
</p>
$$\{T \leq t\} \in \mathcal{F}_t$$
</blockquote>
<p>Note that we cannot swap the inequality for an equals sign in the definition of a stopping time for continuous time processes. Furthermore, porposition 5.5 holds for conitnious time processes if the filtration is right continuous: $\mathcal{F}_t = \mathcal{F}_{t^+}= \bigcap_{s>t} \mathcal{F}_s$.</p>
]]></content:encoded>
    </item>
    <item>
      <title>5.1 - Axiomatic Construction of Stochastic Process</title>
      <link>https://hasithv.github.io/posts/notes/eliasa/chap5/5-1/</link>
      <pubDate>Sat, 03 Aug 2024 16:45:46 -0700</pubDate>
      <guid>https://hasithv.github.io/posts/notes/eliasa/chap5/5-1/</guid>
      <description>Definition of a stochastic process A stochastic process is a parameterized random variable $\{X_t\}_{t\in\mathbf{T}}$ defined on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ taking on values in $\mathbb{R}$. $\mathbf{T}$ can seemingly be any subset of $\mathbb{R}$. For any fixed $t \in \mathbf{T}$, we can define the random variable
$$X_t: \Omega \rightarrow \mathbb{R}, \quad \omega \rightarrowtail X_t(\omega)$$ Thinking of a simple random walk, this means that $X_t$ is a random variable that takes in some subset of $\Omega = \{H,T\}^\mathbb{N}$ and outputs a real valued number (the sum of the first $t$ values in $\omega$): $\{\omega_1, \omega_2, \ldots \} \rightarrow \sum_{n \leq t} X(\omega_n)$</description>
      <content:encoded><![CDATA[<h2 id="definition-of-a-stochastic-process">Definition of a stochastic process</h2>
<p>A stochastic process is a parameterized random variable $\{X_t\}_{t\in\mathbf{T}}$ defined on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ taking on values in $\mathbb{R}$. $\mathbf{T}$ can seemingly be any subset of $\mathbb{R}$. For any fixed $t \in \mathbf{T}$, we can define the random variable</p>
$$X_t: \Omega \rightarrow \mathbb{R}, \quad \omega \rightarrowtail X_t(\omega)$$
<p>Thinking of a simple random walk, this means that $X_t$ is a random variable that takes in some subset of $\Omega = \{H,T\}^\mathbb{N}$ and outputs a real valued number (the sum of the first $t$ values in $\omega$): $\{\omega_1, \omega_2, \ldots \} \rightarrow \sum_{n \leq t} X(\omega_n)$</p>
<p>On the other side of the coin, for a fixed $\omega \in \Omega$, we can define a real-valued measureable function on $\mathbf{T}$ called the trajectory of $X$</p>
$$X_.(\omega): \mathbf{T} \rightarrow \mathbb{R}, \quad t \rightarrowtail X_t(\omega)$$
<p>Again, back to the random walk, this means that we can get a real valued output for any given $t$. To be even more compact, we can say taht a stochastic process is a measureable function from $\Omega \times \mathbf{T}$ to $\mathbb{R}$</p>
$$(\omega, t) \rightarrowtail X(\omega, t) := X_t(\omega)$$
<p>The largest probability space that one can take is the infinite product space $\Omega = \mathbb{R}^\mathbf{T}$. Essentially, this is a space which can takeon any real value at any moment in time (&#x26a0;&#xfe0f; why are we restricting ourselves to $\mathbb{R}$? Why can&rsquo;t it be a vector valued function?)</p>
<p>For finite dimension distributions, we are interested in
</p>
$$\mu_{1,\ldots,t_k}(F_1 \times \ldots \times F_k) = \mathbb{P[X_{t_1}\in F_1, \ldots X_{t_k} \in F_k]}$$
<blockquote>
<p><strong>Theorem 5.2:</strong> (Kolmogorov&rsquo;s extension theorem). Kolmogorov&rsquo;s extension theorem allows us to say, for any $\mu$ invariant under permuting the order of $t_k$ and $F_k$ and also adding additional time points with their associated $F$ being $\mathbb{R}$, that there exists a probability space and a stochastic prcess such that
</p>
$$\mu_{1,\ldots,t_k}(F_1 \times \ldots \times F_k) = \mathbb{P[X_{t_1}\in F_1, \ldots X_{t_k} \in F_k]}$$
</blockquote>
<p>Kolmogorov&rsquo;s extension theorem is very general. In fact, so general that it does not give us a very good idea of what the process actually looks like. Usually, we start with this extremely general definition and then impose stricter conditions to prove that the measure can be defined on a smaller probability space rather than $\Omega$</p>
]]></content:encoded>
    </item>
    <item>
      <title>Applied Stochastic Analysis</title>
      <link>https://hasithv.github.io/posts/notes/eliasa/eliasa/</link>
      <pubDate>Sat, 03 Aug 2024 16:43:39 -0700</pubDate>
      <guid>https://hasithv.github.io/posts/notes/eliasa/eliasa/</guid>
      <description>Here are my notes for E, Li, and Vanden-Eijnden&amp;rsquo;s Applied Stochastic Analysis
Chapter 5 - Stochastic Processes 5.1 - Axiomatic Construction of Stochastic Process 5.2 - Filtration and Stopping Time </description>
      <content:encoded><![CDATA[<p>Here are my notes for E, Li, and Vanden-Eijnden&rsquo;s <a href="https://bookstore.ams.org/gsm-199/"><em>Applied Stochastic Analysis</em></a></p>
<ul>
<li>Chapter 5 - Stochastic Processes
<ul>
<li>5.1 - <a href="/posts/notes/eliasa/chap5/5-1/">Axiomatic Construction of Stochastic Process</a></li>
<li>5.2 - <a href="/posts/notes/eliasa/chap5/5-2/">Filtration and Stopping Time</a></li>
</ul>
</li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>That&#39;s not how Probability Works!</title>
      <link>https://hasithv.github.io/posts/07-29-24-nothowprobabilityworks/</link>
      <pubDate>Tue, 30 Jul 2024 00:07:20 -0700</pubDate>
      <guid>https://hasithv.github.io/posts/07-29-24-nothowprobabilityworks/</guid>
      <description>I was recently doing a probability puzzle that I can&amp;rsquo;t quite remember the context of, but I came across the answer that the probability would be $$\mathbb{P}(X) = n p^n \; \quad \forall \: n\in\mathbb{N}, p \in [0,1].$$ But this is obviously wrong! Plug in $p=.9, n=2$, and you get that $\mathbb{P}(X) = 1.62$. Thaat&amp;rsquo;s not how probability works! However, for $p=0.5$, $\mathbb{P}(X)$ will remain $\leq 1$ for all $n \in \mathbb{N}$.</description>
      <content:encoded><![CDATA[<p>I was recently doing a probability puzzle that I can&rsquo;t quite remember the context of, but I came across the answer that the probability would be
</p>
$$\mathbb{P}(X) = n p^n \; \quad \forall \: n\in\mathbb{N}, p \in [0,1].$$
<p>But this is obviously wrong! Plug in $p=.9, n=2$, and you get that $\mathbb{P}(X) = 1.62$. Thaat&rsquo;s not how probability works! However, for $p=0.5$, $\mathbb{P}(X)$ will remain $\leq 1$ for all $n \in \mathbb{N}$. So, somewhere in the interval $(0.5,0.9)$, we reach a critical value where any $p$ greater than that will result in a probability greater than one, and any value less than it will be a bit more reasonable.</p>
<p>So, what is this critical value that will help me save face?</p>
<p>Well, the question we are trying to answer, phrased a bit more formally, is:</p>
<blockquote>
<p>find the largest $p \in [0,1]$ such that $np^n \leq 1$ for all $n \in \mathbb{N}.$</p>
</blockquote>
<p>First, we rephrase the problem by stating
</p>
$$np^n \leq 1 \iff p^n \leq \frac{1}{n}.$$
<p>Visually, this means that the exponential graph of $f_p(n) = p^n$ can never go above $g_p(n) = \frac{1}{n}$ for some fixed $p$. From this, we can deduce that the critical value of $p$, which we will denote as $p_0$, will satisfy the following relation:</p>
<blockquote>
<p>Given the parametrized forms of $f_p$ and $g_p$
</p>
$$F_{p}(t) = \begin{bmatrix}
t \\
f_p(t)
\end{bmatrix}, \; 
G_p(t) = \begin{bmatrix}
t \\
g_p(t)
\end{bmatrix},$$
<p>
the critical $p_0$ value will be such that
</p>
$$F_{p_0}(t_0) = G_{p_0}(t_0),\text{ and } \dot{F}_{p_0}(t_0) = \lambda \dot{G}_{p_0}(t_0)$$
<p>
for some $\lambda \in \mathbb{R}, t_0 \in \mathbb{R}^+$. In other words, their velocities will point in the same direction (and, perhaps more intuitively, the outward normals of each curve will be parallel, so the graphs &lsquo;kiss&rsquo; at some $t_0$ with the choice of $p_0$).</p>
</blockquote>
<p>Now, we have a fairly simple problem to solve. Because the $x$ component of $F$ and $G$ are always equal, we immediately find that $\lambda = 1$ for their time derivatives to be equal to each other. Now, that leads us to solve for a $p_0$ and $n$ such that
</p>
$$
\begin{aligned}
    f_{p_0}(t_0) &= g_{p_0}(t_0) \\
    \implies p_0^n &= \frac{1}{t_0}
\end{aligned}
$$
<p>
and
</p>
$$
\begin{aligned}
     \dot{f}_{p_0}(t_0) &= \dot{g}_{p_0}(t_0) \\
    \implies -\ln(p_0)p_0^n &= \frac{1}{t_0^2}
\end{aligned}
$$
<p>
So, rather unsatisfyingly, we boiled it down to a system of nonlinear equations
</p>
$$
\begin{cases}
    p_0^n = \frac{1}{t_0}, \\
    \ln(p_0)p_0^n = -\left(\frac{1}{t_0}\right)^2
\end{cases}
$$
<p>
which I cannot solve, but Desmos tells me that $p_0 \approx 0.6922$ and $t_0 \approx 2.7181$.</p>
<p>Thus, my answer would have been reasonable in <em>some</em> convoluted scenario in which $p < 0.6922$.</p>
<p>(This answer, too, is not totally right! This is because there may be a larger $p$ value that satisfies $np^n \leq 1$ for $n \in \mathbb{N}$ but <em>not</em> for $n\in \mathbb{R}^+$. We solved for the $n \in \mathbb{R}^+$ case, which would technically give us a lower bound for $p_0$. Taking this into consideration, our $p_0$ value would really be $p_0 \approx 0.6934$)</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
