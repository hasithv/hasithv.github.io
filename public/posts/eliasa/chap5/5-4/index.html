<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>5.4 - Gaussian Processes | HasithAlted</title>
<meta name="keywords" content="stochastics, probability, lecture">
<meta name="description" content="
Definition 5.9: A stochasitc process $\{X_t\}_{t \geq 0}$ is a Gaussian Process if its finite dimensional distributions are consistent Gaussian measures for any $0 \leq t_1 &lt; t_2 &lt; \ldots &lt; t_k$.
Recall that a Gaussian random vector $\mathbf{X} = (X_1, X_2,\ldots,X_n)^T$ is completely characterized by its first and second moments

$$\mathbf{m} = \mathbb{E}[\mathbf{X}], \quad \mathbf{K} = \mathbb{E}[(\mathbf{X} - \mathbf{m}) (\mathbf{X} - \mathbf{m})^T]$$Meaning that the characteristic function is expressed only in terms of $\mathbf{m}$ and $\mathbf{K}$
">
<meta name="author" content="Hasith Vattikuti">
<link rel="canonical" href="https://hasithv.github.io/posts/eliasa/chap5/5-4/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css" integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF&#43;13Dyqob6ASlTrTye8=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://hasithv.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://hasithv.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://hasithv.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://hasithv.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://hasithv.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://hasithv.github.io/posts/eliasa/chap5/5-4/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><script src="https://cdn.plot.ly/plotly-2.20.0.min.js"></script><meta property="og:url" content="https://hasithv.github.io/posts/eliasa/chap5/5-4/">
  <meta property="og:site_name" content="HasithAlted">
  <meta property="og:title" content="5.4 - Gaussian Processes">
  <meta property="og:description" content=" Definition 5.9: A stochasitc process $\{X_t\}_{t \geq 0}$ is a Gaussian Process if its finite dimensional distributions are consistent Gaussian measures for any $0 \leq t_1 &lt; t_2 &lt; \ldots &lt; t_k$.
Recall that a Gaussian random vector $\mathbf{X} = (X_1, X_2,\ldots,X_n)^T$ is completely characterized by its first and second moments $$\mathbf{m} = \mathbb{E}[\mathbf{X}], \quad \mathbf{K} = \mathbb{E}[(\mathbf{X} - \mathbf{m}) (\mathbf{X} - \mathbf{m})^T]$$Meaning that the characteristic function is expressed only in terms of $\mathbf{m}$ and $\mathbf{K}$ ">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-06T21:17:49-07:00">
    <meta property="article:modified_time" content="2024-08-06T21:17:49-07:00">
    <meta property="article:tag" content="Stochastics">
    <meta property="article:tag" content="Probability">
    <meta property="article:tag" content="Lecture">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="5.4 - Gaussian Processes">
<meta name="twitter:description" content="
Definition 5.9: A stochasitc process $\{X_t\}_{t \geq 0}$ is a Gaussian Process if its finite dimensional distributions are consistent Gaussian measures for any $0 \leq t_1 &lt; t_2 &lt; \ldots &lt; t_k$.
Recall that a Gaussian random vector $\mathbf{X} = (X_1, X_2,\ldots,X_n)^T$ is completely characterized by its first and second moments

$$\mathbf{m} = \mathbb{E}[\mathbf{X}], \quad \mathbf{K} = \mathbb{E}[(\mathbf{X} - \mathbf{m}) (\mathbf{X} - \mathbf{m})^T]$$Meaning that the characteristic function is expressed only in terms of $\mathbf{m}$ and $\mathbf{K}$
">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://hasithv.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "5.4 - Gaussian Processes",
      "item": "https://hasithv.github.io/posts/eliasa/chap5/5-4/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "5.4 - Gaussian Processes",
  "name": "5.4 - Gaussian Processes",
  "description": " Definition 5.9: A stochasitc process $\\{X_t\\}_{t \\geq 0}$ is a Gaussian Process if its finite dimensional distributions are consistent Gaussian measures for any $0 \\leq t_1 \u003c t_2 \u003c \\ldots \u003c t_k$.\nRecall that a Gaussian random vector $\\mathbf{X} = (X_1, X_2,\\ldots,X_n)^T$ is completely characterized by its first and second moments $$\\mathbf{m} = \\mathbb{E}[\\mathbf{X}], \\quad \\mathbf{K} = \\mathbb{E}[(\\mathbf{X} - \\mathbf{m}) (\\mathbf{X} - \\mathbf{m})^T]$$Meaning that the characteristic function is expressed only in terms of $\\mathbf{m}$ and $\\mathbf{K}$ ",
  "keywords": [
    "stochastics", "probability", "lecture"
  ],
  "articleBody": " Definition 5.9: A stochasitc process $\\{X_t\\}_{t \\geq 0}$ is a Gaussian Process if its finite dimensional distributions are consistent Gaussian measures for any $0 \\leq t_1 \u003c t_2 \u003c \\ldots \u003c t_k$.\nRecall that a Gaussian random vector $\\mathbf{X} = (X_1, X_2,\\ldots,X_n)^T$ is completely characterized by its first and second moments $$\\mathbf{m} = \\mathbb{E}[\\mathbf{X}], \\quad \\mathbf{K} = \\mathbb{E}[(\\mathbf{X} - \\mathbf{m}) (\\mathbf{X} - \\mathbf{m})^T]$$Meaning that the characteristic function is expressed only in terms of $\\mathbf{m}$ and $\\mathbf{K}$ $$\\mathbb{E}\\left[e^{i \\mathbf{\\xi} \\cdot \\mathbf{X}}\\right] = e^{i \\mathbf{\\xi} \\cdot \\mathbf{m} - \\frac{1}{2}\\mathbf{\\xi}^T \\mathbf{K} \\mathbf{\\xi}} $$ This means that for any $0 \\leq t_1 \u003c t_2 \u003c \\ldots \u003c t_k$, the measure $\\mu_{t_1, t_2, \\ldots, t_k}$ is uniquely determined by an $\\mathbf{m} = (m(t_1), \\ldots, m(t_k))$ and a covariance matrix $\\mathbf{K}_{ij} = K(t_i, t_j)$. Because our $\\mu$ satisifes the conditions for Kolomorov’s extension theorem, we have a probability space and a stochastic process associated with $\\mu$.\n⚠️ Isn’t one of the conditions of Kolmogorov’s extension theoren that we need to be able to permute the $t_i$? How would this work if we require the $t_i$ to be increasing?\nTheorem 5.10: Assuming that the stochastic process $\\{X_t\\}_{t\\in[0,T]}$ satisfies $$\\mathbb{E} \\left[ \\int_0^T X_t^2 dt \\right] \u003c \\infty$$ then $m \\in L^2_t$. Also, the operator $$\\mathcal{K} f(s) := \\int_0^T K(s,t) f(t) dt$$ is nonnegative, compact on $L^2_t$\nProof: For the first statement, $$\\int_0^T \\mathbb{E}[X]^2 dt \\leq \\int_0^T \\mathbb{E}[X_t^2] dt \u003c \\infty$$ For the second, $$\\begin{align} \\int_0^T \\int_0^T K^2(s,t) ds dt \u0026= \\int_0^T \\int_0^T \\mathbb{E}[\\left((X_t - m(t))(X_s - m(s))\\right)^2]ds dt \\\\ \u0026\\leq \\int_0^T \\int_0^T \\mathbb{E}[(X_t - m(t))^2]\\mathbb{E}[(X_s - m(s))^2]ds dt \\\\ \u0026\\leq \\left( \\int_0^T \\mathbb{E}[X_t] dt \\right) \\\\ \u0026\\leq \\infty \\end{align}$$ which lets us conclude that $K \\in L^2([0,T] \\times [0,T])$, which tells us that $\\mathcal{K}$ is compact on $L^2_t$\n⚠️ I can’t properly find what theorem lets us say the last statement, but I can trust it for now.\nFurthermore, noting that $K$ is symmetric which means that $\\mathcal{K}$ is self adjoint, and we can say $$(\\mathcal{K}f, f) = \\int_0^T \\int_0^T \\mathbb{E}[(X_t - m(t))]\\mathbb{E}[(X_s - m(s))]f(t)f(s) ds dt \\geq 0$$ by symmetry of $s$ and $t$.\nIf we want to extend the characteristic to $L_t$ rather than the finite dimensional version, we can write $$\\mathbb{E}[e^{i(\\xi,X)}] = e^{i(\\xi,m) - \\frac{1}{2} (\\xi, \\mathcal{K} \\xi)}, \\quad \\xi \\in L^2_t$$ With $(\\xi,m) = \\int_a^b \\xi(t) m(t) dt$ and $\\mathcal{K}\\xi (t) = \\int_a^b K(t,s) \\xi(s) ds$. This is a fairly reasonable extrapolation from the finite dimensional case.\nTheorem 5.13: Karhunen-Loeve expansion. Let $(X_t)_{t \\in [0,1]}$ be a Gaussian process with mean 0 and covariance function $K(s,t)$, Assume that $K$ continuous and $\\{\\lambda_k\\}$ be the set of eigenvalues for orthonormal eigenfunctions of $K$, $\\{\\phi_k\\}$. Then, $X_t$ has the representation of $$X_t = \\sum_{k=1}^\\infty \\alpha_k \\sqrt{\\lambda_k} \\phi_k(t)$$ Where $\\alpha_k$ is a standard normal random variable $\\mathscr{N}(0,1)$\n⚠️ I am omitting the proof because I feel the result is easy enough to intuitively grasp, and also it is a little theoretical, so maybe I should revisit it if I get more comfortable with proving covergence in probability.\n",
  "wordCount" : "500",
  "inLanguage": "en",
  "datePublished": "2024-08-06T21:17:49-07:00",
  "dateModified": "2024-08-06T21:17:49-07:00",
  "author":{
    "@type": "Person",
    "name": "Hasith Vattikuti"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://hasithv.github.io/posts/eliasa/chap5/5-4/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "HasithAlted",
    "logo": {
      "@type": "ImageObject",
      "url": "https://hasithv.github.io/favicon.ico"
    }
  }
}
</script>
    
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)'], ['$','$']]                  
    }
  };
</script>


    
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://hasithv.github.io/" accesskey="h" title="HasithAlted (Alt + H)">HasithAlted</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://hasithv.github.io/archives/" title="archives">
                    <span>archives</span>
                </a>
            </li>
            <li>
                <a href="https://hasithv.github.io/categories/notes/" title="notes">
                    <span>notes</span>
                </a>
            </li>
            <li>
                <a href="https://hasithv.github.io/about/" title="about">
                    <span>about</span>
                </a>
            </li>
            <li>
                <a href="https://hasithv.github.io/categories/" title="categories">
                    <span>categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      5.4 - Gaussian Processes
    </h1>
    <div class="post-meta"><span title='2024-08-06 21:17:49 -0700 -0700'>August 6, 2024</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Hasith Vattikuti

</div>
  </header> 
  <div class="post-content"><blockquote>
<p><strong>Definition 5.9:</strong> A stochasitc process $\{X_t\}_{t \geq 0}$ is a <em>Gaussian Process</em> if its finite dimensional distributions are consistent Gaussian measures for any $0 \leq t_1 < t_2 < \ldots < t_k$.</p></blockquote>
<p>Recall that a Gaussian random vector $\mathbf{X} = (X_1, X_2,\ldots,X_n)^T$ is completely characterized by its first and second moments
</p>
$$\mathbf{m} = \mathbb{E}[\mathbf{X}], \quad \mathbf{K} = \mathbb{E}[(\mathbf{X} - \mathbf{m}) (\mathbf{X} - \mathbf{m})^T]$$<p>Meaning that the characteristic function is expressed only in terms of $\mathbf{m}$ and $\mathbf{K}$
</p>
$$\mathbb{E}\left[e^{i \mathbf{\xi} \cdot \mathbf{X}}\right] = e^{i \mathbf{\xi} \cdot \mathbf{m} - \frac{1}{2}\mathbf{\xi}^T \mathbf{K} \mathbf{\xi}} $$<p>
This means that for any $0 \leq t_1 < t_2 < \ldots < t_k$, the measure $\mu_{t_1, t_2, \ldots, t_k}$ is uniquely determined by an $\mathbf{m} = (m(t_1), \ldots, m(t_k))$ and a covariance matrix $\mathbf{K}_{ij} = K(t_i, t_j)$. Because our $\mu$ satisifes the conditions for Kolomorov&rsquo;s extension theorem, we have a probability space and a stochastic process associated with $\mu$.</p>
<p>&#x26a0;&#xfe0f; Isn&rsquo;t one of the conditions of Kolmogorov&rsquo;s extension theoren that we need to be able to permute the $t_i$? How would this work if we require the $t_i$ to be increasing?</p>
<blockquote>
<p><strong>Theorem 5.10:</strong> Assuming that the stochastic process $\{X_t\}_{t\in[0,T]}$ satisfies
</p>
$$\mathbb{E} \left[ \int_0^T X_t^2 dt \right] < \infty$$<p>
then $m \in L^2_t$. Also, the operator
</p>
$$\mathcal{K} f(s) := \int_0^T K(s,t) f(t) dt$$<p>
is nonnegative, compact on $L^2_t$</p></blockquote>
<blockquote>
<p><strong>Proof:</strong> For the first statement,
</p>
$$\int_0^T \mathbb{E}[X]^2 dt \leq \int_0^T \mathbb{E}[X_t^2] dt < \infty$$<p>
For the second,
</p>
$$\begin{align}
\int_0^T \int_0^T K^2(s,t) ds dt &= \int_0^T \int_0^T \mathbb{E}[\left((X_t - m(t))(X_s - m(s))\right)^2]ds dt \\
&\leq \int_0^T \int_0^T \mathbb{E}[(X_t - m(t))^2]\mathbb{E}[(X_s - m(s))^2]ds dt \\
&\leq \left( \int_0^T \mathbb{E}[X_t] dt \right) \\
&\leq \infty 
\end{align}$$<p>
which lets us conclude that $K \in L^2([0,T] \times [0,T])$, which tells us that $\mathcal{K}$ is compact on $L^2_t$</p>
<p>&#x26a0;&#xfe0f; I can&rsquo;t properly find what theorem lets us say the last statement, but I can trust it for now.</p>
<p>Furthermore, noting that $K$ is symmetric which means that $\mathcal{K}$ is self adjoint, and we can say
</p>
$$(\mathcal{K}f, f) = \int_0^T \int_0^T \mathbb{E}[(X_t - m(t))]\mathbb{E}[(X_s - m(s))]f(t)f(s) ds dt \geq 0$$<p>
by symmetry of $s$ and $t$.</p></blockquote>
<p>If we want to extend the characteristic to $L_t$ rather than the finite dimensional version, we can write
</p>
$$\mathbb{E}[e^{i(\xi,X)}] = e^{i(\xi,m) - \frac{1}{2} (\xi, \mathcal{K} \xi)}, \quad \xi \in L^2_t$$<p>
With $(\xi,m) = \int_a^b \xi(t) m(t) dt$ and $\mathcal{K}\xi (t) = \int_a^b K(t,s) \xi(s) ds$. This is a fairly reasonable extrapolation from the finite dimensional case.</p>
<blockquote>
<p><strong>Theorem 5.13:</strong> <em>Karhunen-Loeve expansion</em>. Let $(X_t)_{t \in [0,1]}$ be a Gaussian process with mean 0 and covariance function $K(s,t)$, Assume that $K$ continuous and $\{\lambda_k\}$ be the set of eigenvalues for orthonormal eigenfunctions of $K$, $\{\phi_k\}$. Then, $X_t$ has the representation of
</p>
$$X_t = \sum_{k=1}^\infty \alpha_k \sqrt{\lambda_k} \phi_k(t)$$<p>
Where $\alpha_k$ is a standard normal random variable $\mathscr{N}(0,1)$</p>
<p>&#x26a0;&#xfe0f; I am omitting the proof because I feel the result is easy enough to intuitively grasp, and also it is a little theoretical, so maybe I should revisit it if I get more comfortable with proving covergence in probability.</p></blockquote>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://hasithv.github.io/tags/stochastics/">Stochastics</a></li>
      <li><a href="https://hasithv.github.io/tags/probability/">Probability</a></li>
      <li><a href="https://hasithv.github.io/tags/lecture/">Lecture</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://hasithv.github.io/">HasithAlted</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
